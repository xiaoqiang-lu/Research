# Multimodal Semantic Segmentation

**Multimodal semantic segmentation involves parsing scenes and performing pixel-level classification based on the use of various perceptual modalities, such as optical, depth, infrared, SAR images, etc.**

## Natural Data

**1. Multi-Modal Fusion Transformer for End-to-End Autonomous Driving, _CVPR 2021_**
- Paper: https://openaccess.thecvf.com/content/CVPR2021/papers/Prakash_Multi-Modal_Fusion_Transformer_for_End-to-End_Autonomous_Driving_CVPR_2021_paper.pdf
- Code: https://github.com/autonomousvision/transfuser/tree/cvpr2021
```
@inproceedings{transfuser,
  title={Multi-modal fusion transformer for end-to-end autonomous driving},
  author={Prakash, Aditya and Chitta, Kashyap and Geiger, Andreas},
  booktitle=CVPR,
  pages={7077--7087},
  year={2021}
}
```

**1. Multimodal Token Fusion for Vision Transformers, _CVPR 2022_**
- Paper: https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Multimodal_Token_Fusion_for_Vision_Transformers_CVPR_2022_paper.pdf
- Code: https://github.com/yikaiw/TokenFusion
```
@inproceedings{tokenfusion,
  title={Multimodal token fusion for vision transformers},
  author={Wang, Yikai and Chen, Xinghao and Cao, Lele and Huang, Wenbing and Sun, Fuchun and Wang, Yunhe},
  booktitle=CVPR,
  pages={12186--12195},
  year={2022}
}
```

**1. CMX: Cross-Modal Fusion for RGB-X Semantic Segmentation with Transformers, _TITS 2023_**
- Paper: https://ieeexplore.ieee.org/document/10231003
- Code: https://github.com/huaaaliu/RGBX_Semantic_Segmentation
```
@article{cmx,
  title={CMX: Cross-modal fusion for RGB-X semantic segmentation with transformers},
  author={Zhang, Jiaming and Liu, Huayao and Yang, Kailun and Hu, Xinxin and Liu, Ruiping and Stiefelhagen, Rainer},
  journal=TITS,
  year={2023},
  publisher={IEEE}
}
```

**1. Delivering Arbitrary-Modal Semantic Segmentation, _CVPR 2023_**
- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Delivering_Arbitrary-Modal_Semantic_Segmentation_CVPR_2023_paper.pdf
- Code: https://github.com/jamycheung/DELIVER
```
@inproceedings{cmnext,
  title={Delivering arbitrary-modal semantic segmentation},
  author={Zhang, Jiaming and Liu, Ruiping and Shi, Hao and Yang, Kailun and Rei{\ss}, Simon and Peng, Kunyu and Fu, Haodong and Wang, Kaiwei and Stiefelhagen, Rainer},
  booktitle=CVPR,
  pages={1136--1147},
  year={2023}
}
```

**1. DFormer: Rethinking RGBD Representation Learning for Semantic Segmentation, _ICLR 2024_**
- Paper: https://arxiv.org/abs/2309.09668
- Code: https://github.com/VCIP-RGBD/DFormer
```
@inproceedings{dformer,
  title={Dformer: Rethinking rgbd representation learning for semantic segmentation},
  author={Yin, Bowen and Zhang, Xuying and Li, Zhongyu and Liu, Li and Cheng, Ming-Ming and Hou, Qibin},
  booktitle=ICLR,
  year={2024}
}
```

**1. GeminiFusion: Efficient Pixel-wise Multimodal Fusion for Vision Transformer, _ICML 2024_**
- Paper: https://arxiv.org/abs/2406.01210
- Code: https://github.com/JiaDingCN/GeminiFusion
```
@inproceedings{geminifusion,
  title={GeminiFusion: Efficient Pixel-wise Multimodal Fusion for Vision Transformer},
  author={Jia, Ding and Guo, Jianyuan and Han, Kai and Wu, Han and Zhang, Chao and Xu, Chang and Chen, Xinghao},
  booktitle=ICML,
  year={2024}
}
```


## Remote Sensing Data